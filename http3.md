在HTTP/2.0结尾说到虽然HTTP/2.0解决了HTTP应用层的队头阻塞问题，但是传输层TCP数据包级别的队头阻塞依然存在且无法解决，这是其问题之一
在讲HTTP/3.0之前，先总结下HTTP/2.0存在的几个问题
### TCP 的队头阻塞

先看下TCP是如何传输数据的，参考下图

![](https://pic.imgdb.cn/item/60dad3165132923bf878a572.jpg)

通过上图可以看出来TCP协议在发送端把数据分成了多个有顺序的块，在传输过程中是无需传输的，然后在接收端再按照顺序把数据包组合成原始数据。
可以想象一下，网络传输本身并不是可靠的，当出现网络波动、网络故障的时候就会出现丢包的情况。假如上面传输的TCP包3在传输的过程中丢失了，那么TCP连接就会处于暂停状态等待数据包3的重传，类似于下图

![](https://pic.imgdb.cn/item/60dadb835132923bf8ae133b.jpg)

TCP队头阻塞又是如何影响HTTP/2.0的呢，为了直观的理解下面举个例子
现在服务器需要向浏览器返回两个文件a.css和b.js，首先HTTP/2.0会对每个文件进行二进制分帧并标记上stream id（流 ID），然后一块把需要传输的数据提交给TCP，TCP再根据数据的大小分成不同的数据包进行传输。注意这里HTTP的数据对TCP是不透明的，对于TCP来说它只知道自己需要传输一下数据而已

![](https://pic.imgdb.cn/item/60db0e9f5132923bf89e8d37.jpg)

如果 TCP 数据包2在网络中丢失，但数据包1和数据包3已经到达，会发生什么情况？请记住，TCP并不知道它正在承载 HTTP/2，只知道它需要按顺序传递数据。因此，它知道数据包1的内容可以安全使用，并将这些内容传递给浏览器。然而，它发现数据包1中的字节和数据包3中的字节（放数据包2 的地方）之间存在间隙，因此还不能将数据包3传递给浏览器。TCP 将数据包3保存在其接收缓冲区中，直到它接收到数据包2的重传副本（这至少需要往返服务器一次），之后它可以按照正确的顺序将这两个数据包都传递给浏览器。也就是说：**丢失的数据包2 队头阻塞（HOL blocking）数据包3！**

我们可以看到，TCP 数据包2只携带流id 2（CSS文件）的数据，数据包3同时携带流1（JS文件）和流2的数据。在 HTTP 级别，我们知道这两个流是独立的，通过数据帧可以看出来。因此，理论上我们可以完美地将数据包3传递给浏览器，而不必等待数据包2到达。浏览器将看到流id为1的数据帧，并且能够直接使用它。只有流2必须被挂起，等待数据包2的重新传输。这将比我们从 TCP 的方式中得到的效率更高，TCP 的方式最终会阻塞流1和流2

另一个例子是数据包1丢失，但是接收到2和3的情况。TCP将再次阻止数据包2和3，等待1。但是，我们可以看到，在HTTP/2级别，流2的数据（CSS文件）完全存在于数据包2和3中，不必等待数据包1的重新传输。浏览器本可以完美地解析/处理/使用 CSS 文件，但却被困在等待 JS 文件的重新传输

总之，TCP 不知道 HTTP/2.0 的独立流（streams）这一事实意味着 TCP 层队头阻塞（由于丢失或延迟的数据包）也最终导致 HTTP 队头阻塞！所以随着丢包率的增加，HTTP/2.0 的传输效率也会越来越差。有测试数据表明，当系统达到了 2% 的丢包率时，HTTP/1.1 的传输效率反而比 HTTP/2.0 表现得更好

其实也没必要过分担心丢包率带来的性能影响，虽然数据包丢失确实发生在网络上，但还是比较少见的。特别是在有线网络中，包丢失率只有 0.01%。即使是在最差的蜂窝网络上，在现实中，您也很少看到丢包率高于2%。这与数据包丢失和抖动（网络中的延迟变化）通常是突发性的这一事实结合在一起的。包丢失率为2%并不意味着每100个包中总是有2个包丢失（例如数据包 42 和 96）。实际上大多数情况更像是在总共500个包中丢失10个连续的包。

### TCP 建立连接的延时
除了TCP队头阻塞之外，总所周知TCP的握手也是一个繁琐且效率低下的过程。
在说延时之前先描述一个概念：网络延迟。网络延迟又称RTT（Round Trip Time），表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。

我们看下在建立TCP连接时需要多少个RTT，首先TCP需要三次握手也就是1.5个RTT，如果使用了HTTPS还需要TLS的握手,根据版本不同需要1-2个RTT

所以在建立一个连接之前需要经历3-4个RTT，如果网络比较好物理距离比较近，一个RTT时间可以控制在10毫秒，总共需要30-40毫秒，这样还是可以接受的。但是如果服务器距离比较远，或者网络稍微有点波动那这个时间也许就会达到300-400毫秒，这时就能明显感觉到"慢"了

### HTTP/3.0 QUIC 协议
在说HTTP/3.0之前先聊下一个现状：体系太"成熟"的TCP和UDP协议。为什么这么说呢，现在已经知道了TCP存在队头阻塞和连接建立延时等缺点，那是否能通过更换TCP协议来解决这问题呢？
答案是：基本不可能，主要有以下原因
第一是网络中间设备僵化，在网络之间会有很多中间设备，比如路由器、交换机、NAT等等，他们使用的软件基本上都是大量依赖TCP、UDP协议，而且很少会更新升级。TCP协议长达几十年在互联网通信里的垄断地位，想要根本性地优化或改进TCP协议，难度相当大
第二个原因是TCP、UDP都是内置在操作系统内的，由操作系统内核来实现，上层应用程序是无法修改的，只能使用。这就意味着个人想要自由的更新升级他们也是非常困难的

HTTP/3.0要思考的问题就是，虽然TCP有缺陷但是由于上面的原因无法通过修改TCP本身来解决。那么解决问题的思路就是绕过TCP协议，发明一个新的协议，不过这样同样面临着上面的问题，因为中间设备只认识TCP、UDP， 新协议的推广会更难
因此HTTP/3选择了一个折中的方式，用UDP替换TCP来传输数据。基于 UDP 实现了类似于 TCP 的多路数据流、传输可靠性等功能，这套功能称为 QUIC 协议。参考下图

![](https://pic.imgdb.cn/item/60dc52e95132923bf8340d19.jpg)

具体说下QUIC协议的功能点
- **多路数据流** 和TCP不一样，QUIC可以在同一物理链路上实现多个逻辑数据流的传输，如果传输过程中丢失了某个包也不会阻塞整个链路。这样也就解决了TCP的队头阻塞问题，如下图

![](https://pic.imgdb.cn/item/60dc55045132923bf83e04bc.jpg)

- **集成 TLS** 目前QUIC使用 TLS1.3，相比之前消耗更少RTT

- **可靠性、流量控制** 虽然 UDP 不提供可靠性的传输，但 QUIC 在 UDP 的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些 TCP 中存在的特性。且这些控制权在应用层，并非像TCP在系统内核

- **快速握手** QUIC 协议可以在 0 到 1 个RTT 内，完成连接的创建（包括 TLS）

当然还有其他更多的细节功能，这里就不一一列举了

### QUIC协议这么好，可以大规模切换为QUIC吗

理想和现实总是有一定的差距，理论上HTTP/3 是个比较完美的协议。不过想在实际环境中应用还是有很大难度的，主要有以下几个方面
- 第一个就是浏览器和服务器的支持问题，像常用的web服务器nginx、apache都未支持QUIC，目前即使是支持了QUIC（例如Chrome），但是在实现上不同的软件和端之间还是存在着比较大的差异

- 操作系统对UDP协议的优化问题。由于使用规模和场景原因，系统内核对UDP的的优化远没有达到对TCP的优化程度

- 中间设备对UDP协议的优化问题。跟上面问题其实是一个问题，这些设备对UDP的优化程度也是不如TCP的。据统计在使用QUIC协议时，丢包率能到达3%～7%

### 最后
QUIC 协议开创性的使用了 UDP 协议作为底层传输协议，通过各种方式减少了网络延迟。

虽然目前 QUIC 在理论和实践上都是可行且高效的，但离大范围普及还有较长的一段距离，期待 QUIC 协议规范能够成为终稿，并在除了谷歌浏览器之外的其他浏览器和应用服务器中也能够实现












